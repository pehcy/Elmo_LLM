{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pehcy/miniconda3/envs/denisllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_dataset = load_dataset('tatsu-lab/alpaca', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 52002\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(alpaca_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = alpaca_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "UNK_token = 1\n",
    "SOS_token = 2\n",
    "EOS_token = 3\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, name) -> None:\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            PAD_token: \"<pad>\",\n",
    "            UNK_token: \"<unk>\",\n",
    "            SOS_token: \"<sos>\",\n",
    "            EOS_token: \"<eos>\"\n",
    "        }\n",
    "        self.num_words = 4\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        \n",
    "        self.trimmed = True\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "        \n",
    "        # reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            PAD_token: \"<pad>\",\n",
    "            UNK_token: \"<unk>\",\n",
    "            SOS_token: \"<sos>\",\n",
    "            EOS_token: \"<eos>\"\n",
    "        }\n",
    "        self.num_words = 4\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalize_str(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocabs(datatable: pd.DataFrame, corpus_name=\"alpaca\"):\n",
    "    output_col = datatable['output'].to_list()\n",
    "    instruction_col = datatable['instruction'].to_list()\n",
    "    pairs = [[normalize_str(x), normalize_str(y)] for x, y in zip(instruction_col, output_col)]\n",
    "    voc = Vocab(corpus_name)\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_col = data['output'].to_list()\n",
    "#instruction_col = data['instruction'].to_list()\n",
    "#a = [[normalize_str(x), normalize_str(y)] for x, y in zip(instruction_col, output_col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__MAX_LEN_KV_PAIR = 50\n",
    "\n",
    "def is_under_maxlen(p):\n",
    "    return len(p[0].split(' ')) < __MAX_LEN_KV_PAIR and len(p[1].split(' ')) < __MAX_LEN_KV_PAIR\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if is_under_maxlen(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepare_data(datatable: pd.DataFrame, save_dir):\n",
    "    print(\"Start prepraing data...\")\n",
    "    voc, pairs = read_vocabs(datatable, \"alpaca\")\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.add_sentence(pair[0])\n",
    "        voc.add_sentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "\n",
    "    with open('word_map.json', 'w') as p:\n",
    "        json.dump(voc.word2index, p)\n",
    "\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prepraing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 52002 sentence pairs\n",
      "Trimmed to 45912 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 36341\n",
      "['give three tips for staying healthy .', '.eat a balanced diet and make sure to include plenty of fruits and vegetables . . exercise regularly to keep your body active and strong . . get enough sleep and maintain a consistent sleep schedule .']\n",
      "['what are the three primary colors ?', 'the three primary colors are red blue and yellow .']\n",
      "['describe the structure of an atom .', 'an atom is made up of a nucleus which contains protons and neutrons surrounded by electrons that travel in orbits around the nucleus . the protons and neutrons have a positive charge while the electrons have a negative charge resulting in an overall neutral atom . the number of each particle determines the atomic number and the type of atom .']\n",
      "['how can we reduce air pollution ?', 'there are a number of ways to reduce air pollution such as shifting to renewable energy sources encouraging the use of public transportation prohibiting the burning of fossil fuels implementing policies to reduce emissions from industrial sources and implementing vehicle emissions standards . additionally individuals can do their part to reduce air pollution by reducing car use avoiding burning materials such as wood and changing to energy efficient appliances .']\n",
      "['identify the odd one out .', 'telegram']\n",
      "['explain why the following fraction is equivalent to', 'the fraction is equivalent to because both numerators and denominators are divisible by . dividing both the top and bottom numbers by yields the fraction .']\n",
      "['render a d model of a house', 'nooutput this type of instruction cannot be fulfilled by a gpt model .']\n",
      "['evaluate this sentence for spelling and grammar mistakes', 'he finished his meal and left the restaurant .']\n",
      "['how did julius caesar die ?', 'julius caesar was assassinated by a group of up to conspirators led by gaius cassius longinus and marcus junius brutus in the senate house on the ides of march march of bc .']\n",
      "['what is the capital of france ?', 'the capital of france is paris .']\n"
     ]
    }
   ],
   "source": [
    "voc, pairs = load_prepare_data(data, \"\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "__MIN_COUNT_WORD = 3\n",
    "\n",
    "def trim_rare_words(voc, pairs, min_count = __MIN_COUNT_WORD):\n",
    "    # trim words used under the minimum count\n",
    "    voc.trim(min_count)\n",
    "    # filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        \n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "        \n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "    \n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed from 45912 pairs to 33897, 0.7383 of total\n"
     ]
    }
   ],
   "source": [
    "pairs = trim_rare_words(voc, pairs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def indexes_from_sentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zero_padding(l, fill_value=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fill_value))\n",
    "\n",
    "def input_encode(l, voc):\n",
    "    indexes_batch = [indexes_from_sentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    return pad_var, lengths\n",
    "\n",
    "def output_encode(l, voc):\n",
    "    indexes_batch = [indexes_from_sentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    return pad_var, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5553, 3],\n",
       " [4130, 3],\n",
       " [11, 3],\n",
       " [582, 3],\n",
       " [879, 879, 3],\n",
       " [11, 3],\n",
       " [489, 3],\n",
       " [1218, 3],\n",
       " [879, 879, 3],\n",
       " [582, 3],\n",
       " [4130, 3],\n",
       " [1218, 3],\n",
       " [879, 879, 3],\n",
       " [582, 3],\n",
       " [4130, 3],\n",
       " [489, 3],\n",
       " [1218, 3],\n",
       " [1218, 3],\n",
       " [879, 879, 3],\n",
       " [3646, 3],\n",
       " [489, 3],\n",
       " [350, 3],\n",
       " [1008, 3],\n",
       " [11, 3],\n",
       " [489, 3],\n",
       " [652, 3],\n",
       " [879, 879, 3],\n",
       " [457, 3],\n",
       " [4212, 3],\n",
       " [4514, 3],\n",
       " [4212, 3],\n",
       " [489, 3],\n",
       " [419, 3],\n",
       " [879, 879, 3],\n",
       " [41, 3],\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indexes_from_sentence(voc, word) for word in pairs[0][0]] + [PAD_token] * (200 - len(pairs[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(voc, words):\n",
    "    word_map = voc.word2index\n",
    "    enc_c = [word_map.get(word, UNK_token) for word in words]\n",
    "    return enc_c\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "def encode_question(voc, sentence):\n",
    "    words = sentence.split(' ')\n",
    "    enc_c = indexes_from_sentence(voc, words) + [PAD_token] * (max_len - len(words))\n",
    "    return enc_c\n",
    "\n",
    "def encode_answer(voc, sentence):\n",
    "    words = sentence.split(' ')\n",
    "    enc_c = [SOS_token] + indexes_from_sentence(voc, words) + [EOS_token] + [PAD_token] * (max_len - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_encoded = []\n",
    "for pair in pairs:\n",
    "    qus = encode_question(voc, pair[0])\n",
    "    ans = encode_answer(voc, pair[1])\n",
    "    pairs_encoded.append([qus, ans])\n",
    "\n",
    "with open('pairs_encoded.json', 'w') as p:\n",
    "    json.dump(pairs_encoded, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "a = json.load(open('pairs_encoded.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45, 38, 46, 20, 47, 48, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = torch.LongTensor(a[1][0])\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlpacaDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        self.pairs = json.load(open('pairs_encoding.json'))\n",
    "        self.dataset_size = len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        question = torch.LongTensor(self.pairs[index][0])\n",
    "        answer = torch.LongTensor(self.pairs[index][1])\n",
    "\n",
    "        return question, answer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pairs_encoding.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\u001b[43mAlpacaDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      2\u001b[0m                                            batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                            shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      4\u001b[0m                                            pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m, in \u001b[0;36mAlpacaDataset.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpairs_encoding.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairs)\n",
      "File \u001b[0;32m~/miniconda3/envs/denisllm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pairs_encoding.json'"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(AlpacaDataset(),\n",
    "                                           batch_size = 100, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['create open ended questions about a given topic .',\n",
       "  '. what are the advantages and disadvantages of d printing ? . how is d printing being used in various industries ? . what are the main components of a d printing machine ? . how does the technology of d printing work ? . what are the current trends in d printing ?'],\n",
       " ['describe a real world application of reinforcement learning .',\n",
       "  'reinforcement learning has been used in a variety of real world applications such as robotics healthcare and finance . for instance robotics applications use reinforcement learning for end to end control where an agent i .e . a robot learns to maximize a reward by taking an action in an environment . in healthcare reinforcement learning can be used to develop treatments and optimize health systems . in finance reinforcement learning has been used to develop strategies for stock trading and portfolio management .'],\n",
       " ['explain how technology affects communication between people .',\n",
       "  'technology has had a major impact on the way people communicate with each other . it has allowed for the development of faster more reliable ways of communicating such as email instant messaging and video conferencing . these technologies have broken the barriers of distance and time and have made connecting with someone thousands of miles away just as easy as connecting with someone down the street . additionally they have enabled people to exchange larger amounts of information at a much faster rate making communication more effective and efficient .'],\n",
       " ['describe the structure of an atom .',\n",
       "  'an atom is made up of a nucleus which contains protons and neutrons surrounded by electrons that travel in orbits around the nucleus . the protons and neutrons have a positive charge while the electrons have a negative charge resulting in an overall neutral atom . the number of each particle determines the atomic number and the type of atom .'],\n",
       " ['do the following equation', '']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "pair_batch = [random.choice(pairs) for _ in range(5)]\n",
    "pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "pair_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch = [], []\n",
    "for pair in pair_batch:\n",
    "    input_batch.append(pair[0])\n",
    "    output_batch.append(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['create open ended questions about a given topic .',\n",
       " 'describe a real world application of reinforcement learning .',\n",
       " 'explain how technology affects communication between people .',\n",
       " 'describe the structure of an atom .',\n",
       " 'do the following equation']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, lengths = input_encode(input_batch, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 554,  201, 1777,  201,  201],\n",
       "        [ 640, 1777,  908, 1777, 5029],\n",
       "        [1777,  143, 4436,  143,    1],\n",
       "        [  11,  554, 5451,  554,  846],\n",
       "        [ 846,  640,   11,  640, 4922],\n",
       "        [1777,  127,  127,  127, 1777],\n",
       "        [   1, 3601, 1154, 3601,    1],\n",
       "        [5029, 1777,    1, 1777,  555],\n",
       "        [4436,    1, 4922,    1, 5029],\n",
       "        [1777,   11, 5029,  846, 5451],\n",
       "        [1154,    1, 6577, 4922, 5451],\n",
       "        [   1,  640,    1, 1777, 5029],\n",
       "        [1777, 1777,  846,    1, 6577],\n",
       "        [1154,   11, 1777,  143,  127],\n",
       "        [ 201, 5451,  554,  846, 1154],\n",
       "        [1777,    1, 4922,  640, 2054],\n",
       "        [ 201, 6577, 1154, 1848,    1],\n",
       "        [   1, 5029, 5029,  554, 1777],\n",
       "        [4591,  640, 5451,  846, 4591],\n",
       "        [1848, 5451, 5029, 1848, 1848],\n",
       "        [1777,  201, 2054,  640,   11],\n",
       "        [ 143,    1,  909, 1777,  846],\n",
       "        [ 846,   11,    1,    1,  127],\n",
       "        [ 127, 4436,   11, 5029, 5029],\n",
       "        [5029, 4436,  555,  555, 1154],\n",
       "        [1154, 5451,  555,    1,    0],\n",
       "        [ 143,  127, 1777,   11,    0],\n",
       "        [   1,  554,  554, 1154,    0],\n",
       "        [  11,   11,  846,    1,    0],\n",
       "        [3601,  846,  143,   11,    0],\n",
       "        [5029,  127,    1,  846,    0],\n",
       "        [1848, 5029,  554, 5029,    0],\n",
       "        [ 846, 1154, 5029, 1345,    0],\n",
       "        [   1,    1, 1345,    1,    0],\n",
       "        [  11, 5029, 1345,   10,    0],\n",
       "        [   1,  555, 1848,    0,    0],\n",
       "        [2054,    1, 1154,    0,    0],\n",
       "        [ 127,  640,  127,    0,    0],\n",
       "        [5551, 1777,  554,    0,    0],\n",
       "        [1777,  127,   11,    0,    0],\n",
       "        [1154, 1154,  846,    0,    0],\n",
       "        [   1,  555,  127,    0,    0],\n",
       "        [ 846, 5029, 5029,    0,    0],\n",
       "        [5029,  640, 1154,    0,    0],\n",
       "        [4436,  554,    1,    0,    0],\n",
       "        [ 127, 1777, 3601,    0,    0],\n",
       "        [ 554, 1345, 1777,    0,    0],\n",
       "        [   1, 1777,  846,    0,    0],\n",
       "        [  10, 1154, 6577,    0,    0],\n",
       "        [   0,  846, 1777,    0,    0],\n",
       "        [   0,    1, 1777,    0,    0],\n",
       "        [   0, 5451, 1154,    0,    0],\n",
       "        [   0, 1777,    1,    0,    0],\n",
       "        [   0,   11, 4436,    0,    0],\n",
       "        [   0,  640, 1777,    0,    0],\n",
       "        [   0, 1154, 5029,    0,    0],\n",
       "        [   0,  127, 4436,    0,    0],\n",
       "        [   0, 1154, 5451,    0,    0],\n",
       "        [   0, 2054, 1777,    0,    0],\n",
       "        [   0,    1,    1,    0,    0],\n",
       "        [   0,   10,   10,    0,    0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = output_encode(output_batch, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([558, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (question, reply) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(question)\n",
      "File \u001b[0;32m~/miniconda3/envs/denisllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/denisllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/denisllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/denisllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mAlpacaDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     answer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairs[index][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m question, answer\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "for i, (question, reply) in enumerate(train_loader):\n",
    "    if i < 10:\n",
    "        print(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denisllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
